{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled.csv')\n",
    "df['comment'] = df['comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>верблюдов-то за что? дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>страницу обнови, дебил. это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14407</td>\n",
       "      <td>вонючий совковый скот прибежал и ноет. а вот и...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14408</td>\n",
       "      <td>а кого любить? гоблина тупорылого что-ли? или ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14409</td>\n",
       "      <td>посмотрел утомленных солнцем 2. и оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14410</td>\n",
       "      <td>крымотред нарушает правила раздела т.к в нем н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14411</td>\n",
       "      <td>до сих пор пересматриваю его видео. орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "0                   верблюдов-то за что? дебилы, бл...\\n    1.0\n",
       "1      хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                              собаке - собачья смерть\\n    1.0\n",
       "3      страницу обнови, дебил. это тоже не оскорблени...    1.0\n",
       "4      тебя не убедил 6-страничный пдф в том, что скр...    1.0\n",
       "...                                                  ...    ...\n",
       "14407  вонючий совковый скот прибежал и ноет. а вот и...    1.0\n",
       "14408  а кого любить? гоблина тупорылого что-ли? или ...    1.0\n",
       "14409  посмотрел утомленных солнцем 2. и оказалось, ч...    0.0\n",
       "14410  крымотред нарушает правила раздела т.к в нем н...    1.0\n",
       "14411  до сих пор пересматриваю его видео. орамбо кст...    0.0\n",
       "\n",
       "[14401 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.comment.str.contains(\"http\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenizer(text):\n",
    "    return re.split('[_,][=][-][:][;][*][/][\\n][)][(]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /zfs/hybrilit.jinr.ru/user/m/myakotin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>абортмахер</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>анал</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>анус</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>армячок</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>архамудия</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3976</td>\n",
       "      <td>ёбарь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3977</td>\n",
       "      <td>ёбвашумать</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3978</td>\n",
       "      <td>ёбкай</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3979</td>\n",
       "      <td>ёбнуть</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>ёбс</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3981 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  y\n",
       "0     абортмахер  1\n",
       "1           анал  1\n",
       "2           анус  1\n",
       "3        армячок  1\n",
       "4      архамудия  1\n",
       "...          ... ..\n",
       "3976       ёбарь  1\n",
       "3977  ёбвашумать  1\n",
       "3978       ёбкай  1\n",
       "3979      ёбнуть  1\n",
       "3980         ёбс  1\n",
       "\n",
       "[3981 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = pd.read_csv('bad_words.txt', header=None)\n",
    "y_bad  = np.array([1 for i in range(len(bad_words))])\n",
    "bad_words['y'] = y_bad\n",
    "bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>абажур</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>абажура</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>абажурам</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>абажурами</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>абажурах</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532624</td>\n",
       "      <td>посмурневшему</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532625</td>\n",
       "      <td>посмурневшею</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532626</td>\n",
       "      <td>посмурневши</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532627</td>\n",
       "      <td>посмурневшие</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532628</td>\n",
       "      <td>посмурневший</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1532614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0  y\n",
       "15              абажур  0\n",
       "16             абажура  0\n",
       "17            абажурам  0\n",
       "18           абажурами  0\n",
       "19            абажурах  0\n",
       "...                ... ..\n",
       "1532624  посмурневшему  0\n",
       "1532625   посмурневшею  0\n",
       "1532626    посмурневши  0\n",
       "1532627   посмурневшие  0\n",
       "1532628   посмурневший  0\n",
       "\n",
       "[1532614 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_words = pd.read_csv('good_words.txt', header=None)[15:]\n",
    "y_good  = np.array([0 for i in range(len(good_words))])\n",
    "good_words['y'] = y_good\n",
    "good_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4826.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.concatenate((df['comment'].values, bad_words[0].values, good_words[0].values), axis=0)\n",
    "#y = np.concatenate((df['toxic'].values, bad_words['y'].values, good_words['y'].values), axis=0)\n",
    "X = np.concatenate((df['comment'].values, bad_words[0].values), axis=0)\n",
    "y = np.concatenate((df['toxic'].values, bad_words['y'].values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9586.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y) - sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18393"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:14000]\n",
    "y_train = y[:14000]\n",
    "X_test = X[14000:]\n",
    "y_test = y[14000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1300000]\n",
    "y_train = y[:1300000]\n",
    "X_test = X[1300000:]\n",
    "y_test = y[1300000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0,\n",
       "                                         100.0],\n",
       "                          'clf__fit_prior': [True, False],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [['и', 'в', 'во', 'не', 'что',\n",
       "                                                'он', 'на', 'я', 'с', 'со',\n",
       "                                                'как', 'а', 'то', 'все', 'она',\n",
       "                                                'так', 'его', 'но', 'да', 'ты',\n",
       "                                                '...\n",
       "                         {'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0,\n",
       "                                         100.0],\n",
       "                          'clf__fit_prior': [True, False],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__stop_words': [['и', 'в', 'во', 'не', 'что',\n",
       "                                                'он', 'на', 'я', 'с', 'со',\n",
       "                                                'как', 'а', 'то', 'все', 'она',\n",
       "                                                'так', 'его', 'но', 'да', 'ты',\n",
       "                                                'к', 'у', 'же', 'вы', 'за',\n",
       "                                                'бы', 'по', 'только', 'ее',\n",
       "                                                'мне', ...],\n",
       "                                               None],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                       lowercase=True,\n",
    "                       preprocessor=None)\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer],\n",
    "              'clf__fit_prior':[True, False],\n",
    "              'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__use_idf':[False],\n",
    "              'vect__norm':[None],\n",
    "              'clf__fit_prior':[True, False],\n",
    "              'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0, 100.0]}]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                    ('clf', MultinomialNB())])\n",
    "nb_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                          scoring='f1_weighted',\n",
    "                          cv=5, verbose=2,\n",
    "                          n_jobs=-1)\n",
    "nb_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший набор параметров: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__use_idf': False}\n",
      "Правильность при перекрестной проверке: 0.865\n",
      "Правильность при испытании: 0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Наилучший набор параметров: %s'\n",
    "     % nb_tfidf.best_params_)\n",
    "print('Правильность при перекрестной проверке: %.3f'\n",
    "     % nb_tfidf.best_score_)\n",
    "\n",
    "\n",
    "print('Правильность при испытании: %.3f'\n",
    "     % recall_score(nb_tfidf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0,\n",
       "                                         100.0],\n",
       "                          'clf__fit_prior': [True, False],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [['и', 'в', 'во', 'не', 'что',\n",
       "                                                'он', 'на', 'я', 'с', 'со',\n",
       "                                                'как', 'а', 'то', 'все', 'она',\n",
       "                                                'так', 'его', 'но', 'да', 'ты',\n",
       "                                                '...\n",
       "                         {'clf__alpha': [0.001, 0.01, 0.1, 1.0, 5.0, 10.0,\n",
       "                                         100.0],\n",
       "                          'clf__fit_prior': [True, False],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__stop_words': [['и', 'в', 'во', 'не', 'что',\n",
       "                                                'он', 'на', 'я', 'с', 'со',\n",
       "                                                'как', 'а', 'то', 'все', 'она',\n",
       "                                                'так', 'его', 'но', 'да', 'ты',\n",
       "                                                'к', 'у', 'же', 'вы', 'за',\n",
       "                                                'бы', 'по', 'только', 'ее',\n",
       "                                                'мне', ...],\n",
       "                                               None],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'хуйло пидорское'\n",
    "nb_tfidf.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05206134, 0.94793866]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf.predict_proba([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'привет мама'\n",
    "nb_tfidf.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if nb_tfidf.predict_proba([test])[0][0] > 0.12:\n",
    "    print(0)\n",
    "else:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993845682179329"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf.score(good_words[0].values, good_words['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992458521870287"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf.score(bad_words[0].values, bad_words['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "s = pickle.dump(nb_tfidf, open(os.path.join('model_new.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
